{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"nb_files/intro.jpg\">\n",
    "<style TYPE=\"text/css\">\n",
    "code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}\n",
    "</style>\n",
    "<script type=\"text/x-mathjax-config\">\n",
    "MathJax.Hub.Config({\n",
    "    tex2jax: {\n",
    "        inlineMath: [['$','$'], ['\\\\(','\\\\)']],\n",
    "        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry\n",
    "    }\n",
    "});\n",
    "MathJax.Hub.Queue(function() {\n",
    "    var all = MathJax.Hub.getAllJax(), i;\n",
    "    for(i = 0; i < all.length; i += 1) {\n",
    "        all[i].SourceElement().parentNode.className += ' has-jax';\n",
    "    }\n",
    "});\n",
    "</script>\n",
    "<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full\"></script>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "I landed at about 9 and missed pretty much the entire first Sunday of the regular season. The Dolphins had lost the 1 PM game by about 40 to the Ravens and the idea of them beating any other team in the league was unimaginable. As I got into my Uber home from the airport, I realized that meant picking against them was likely an effective but also popular strategy for a survivor league. I started counting the number of teams I could play against the Dolphins without repeats to see how long this strategy was viable. This quickly lead to the idea of an optimization challenge as it satisfies two main criteria:\n",
    "1. It has a calculatable thing to maximize: evaluating a potential pick set can be done using data (though with questionable accuracy)\n",
    "2. It has a constraint that makes it non-trivial: Being able to pick each team once is a simple rule that has just enough complexity to make things interesting\n",
    "\n",
    "The optimization problem is defined by these two pieces and one extra parameter-: the time horizon. The length that the league goes for is a variable that adds a layer of complexity. If the expectation is for the league to last for 1 week, the best first pick will probably look different from the best first pick if the league were to last for 16 weeks.\n",
    "\n",
    "For simplicity, we will make this an assumed parameter in our optimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "I am formalizing the problem here for anyone who cares to see it.\n",
    "\n",
    "Let\n",
    "$H = \\text{Time Horizon,}$\n",
    "\n",
    "$X_{tw} = \\text{1 if team t is picked at week w, 0 otherwise}$\n",
    "\n",
    "$P_{tw} = \\text{Probability that team t wins at week w}$\n",
    "\n",
    "$T = \\text{the set of all teams}$\n",
    "\n",
    "$T_{w} = \\text{the set of teams playing at week w}$\n",
    "\n",
    "### Objective Function\n",
    "\n",
    "We would like to maximize the likelihood that our pickset survives the duration of the time.\n",
    "\n",
    "$P(\\text{pickset all wins})=P(\\text{pick 1 wins, pick 2 wins,...})=P(\\text{pick 1 wins})...P(\\text{pick H wins})$\n",
    "\n",
    "So in convoluted notation, our objective function is \n",
    "\n",
    "$\\max {\\prod\\limits_{i=1}^{H} \\sum\\limits_{t \\in T_i}  P_{ti}X_{ti}}$\n",
    "\n",
    "### Constraints\n",
    "\n",
    "The constraints are one team per week,\n",
    "\n",
    "$ \\sum\\limits_{t \\in T_i} X_{tw} = 1, \\forall i \\in [1,H]$\n",
    "\n",
    "teams selected at most once,\n",
    "\n",
    "$ \\sum\\limits_{i=1}^{H} X_{ti} \\leq 1, \\forall t \\in T$\n",
    "\n",
    "\n",
    "This looks like a pretty good linear programming question, which is not how I approached it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data behind evaluation\n",
    "\n",
    "FiveThirtyEight has maintained a set of ELO scores that characterize the strength of a team based on a historical data. ELO scores are designed to project probability of one team winning over another. This means that using their data and probability projections, I can score any pickset by calculating the joint probability as the product of the individual win probabilities of my picks. The optimization is clearly limited by the accuracy of the data, but as always, the data driven solution serves as a decision support tool rather than the decision itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>elo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NE</td>\n",
       "      <td>1661.355272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>KC</td>\n",
       "      <td>1622.148729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>1616.754464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LAR</td>\n",
       "      <td>1611.252716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LAC</td>\n",
       "      <td>1599.727360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>BAL</td>\n",
       "      <td>1598.557710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PHI</td>\n",
       "      <td>1589.200034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>SEA</td>\n",
       "      <td>1568.437337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1561.645312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>MIN</td>\n",
       "      <td>1559.316056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1554.222031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>TEN</td>\n",
       "      <td>1553.473791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>PIT</td>\n",
       "      <td>1551.694436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>IND</td>\n",
       "      <td>1547.099123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>HOU</td>\n",
       "      <td>1509.570670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>CAR</td>\n",
       "      <td>1506.141723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1499.423723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>GB</td>\n",
       "      <td>1489.807271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>DET</td>\n",
       "      <td>1488.694482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>SF</td>\n",
       "      <td>1457.756782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>BUF</td>\n",
       "      <td>1455.390818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>JAX</td>\n",
       "      <td>1435.177771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>WSH</td>\n",
       "      <td>1433.335317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1428.733404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>NYG</td>\n",
       "      <td>1427.717829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>OAK</td>\n",
       "      <td>1425.871408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>CIN</td>\n",
       "      <td>1425.507827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1421.319814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>TB</td>\n",
       "      <td>1409.647711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1387.160301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>ARI</td>\n",
       "      <td>1385.565349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>NYJ</td>\n",
       "      <td>1377.999306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team          elo\n",
       "0    NE  1661.355272\n",
       "1    KC  1622.148729\n",
       "2    NO  1616.754464\n",
       "3   LAR  1611.252716\n",
       "4   LAC  1599.727360\n",
       "5   BAL  1598.557710\n",
       "6   PHI  1589.200034\n",
       "7   SEA  1568.437337\n",
       "8   DAL  1561.645312\n",
       "9   MIN  1559.316056\n",
       "10  CHI  1554.222031\n",
       "11  TEN  1553.473791\n",
       "12  PIT  1551.694436\n",
       "13  IND  1547.099123\n",
       "14  HOU  1509.570670\n",
       "15  CAR  1506.141723\n",
       "16  ATL  1499.423723\n",
       "17   GB  1489.807271\n",
       "18  DET  1488.694482\n",
       "19   SF  1457.756782\n",
       "20  BUF  1455.390818\n",
       "21  JAX  1435.177771\n",
       "22  WSH  1433.335317\n",
       "23  DEN  1428.733404\n",
       "24  NYG  1427.717829\n",
       "25  OAK  1425.871408\n",
       "26  CIN  1425.507827\n",
       "27  CLE  1421.319814\n",
       "28   TB  1409.647711\n",
       "29  MIA  1387.160301\n",
       "30  ARI  1385.565349\n",
       "31  NYJ  1377.999306"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f38_elo_snapshot = pd.read_csv('data/raw/nfl_elo_latest_2019-09-09.csv')\n",
    "\n",
    "# Add a week variable\n",
    "season_start =  datetime.strptime('2019-09-05', '%Y-%m-%d')\n",
    "f38_elo_snapshot['days_into_season'] = [datetime.strptime(d, '%Y-%m-%d') - season_start for d in f38_elo_snapshot.date]\n",
    "f38_elo_snapshot['week'] = [math.floor(dis.days / 7) + 1 for dis in f38_elo_snapshot.days_into_season]\n",
    "\n",
    "f38_elo_snapshot = f38_elo_snapshot[f38_elo_snapshot.week <= 17].copy()\n",
    "\n",
    "team1_elo = f38_elo_snapshot[['team1', 'elo1_post']]\n",
    "team1_elo = team1_elo[team1_elo.elo1_post.notnull()].copy()\n",
    "team1_elo.columns = ['team', 'elo']\n",
    "team2_elo = f38_elo_snapshot[['team2', 'elo2_post']]\n",
    "team2_elo = team2_elo[team2_elo.elo2_post.notnull()].copy()\n",
    "team2_elo.columns = ['team', 'elo']\n",
    "team_elo = team1_elo.append(team2_elo, ignore_index=True)\n",
    "team_elo.sort_values('elo', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the problem trivial?\n",
    "\n",
    "The problem is trivial if an intuitive, simple strategy can yield the optimal results. If the best strategy is something I can execute by looking at a list of numbers, then the problem does not need to be solved via optimization algorithms. \n",
    "\n",
    "The simplest greedy strategy is to pick the best matchup available each week. For a slightly better greedy baseline, I start with the most lop-sided matchup and eliminate the team and the week until every week has a pick. This will be what I call the greedy strategy for the remainder of the analysis.\n",
    "\n",
    "I evaluate the greedy strategy by seeing where the chosen greedy best pickset falls in the universe of all valid picksets. At small time horizons, there are few enough pickset combinations to compare where the greedy solution ranks as the globally best pickset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving home team related variables so I can add that advantage\n",
    "pick_candidates = f38_elo_snapshot[['week', 'team1', 'team2', 'neutral', 'elo_prob1','elo_prob2']]\n",
    "\n",
    "pick_candidates_1 = pick_candidates[['week', 'team1', 'elo_prob1', 'neutral']].copy()\n",
    "pick_candidates_1['is_team1'] = [False if neu == 1 else True for neu in pick_candidates_1.neutral]\n",
    "pick_candidates_1.columns = ['week', 'team', 'probability', 'neutral','is_home']\n",
    "\n",
    "pick_candidates_2 = pick_candidates[['week', 'team2', 'elo_prob2', 'neutral']].copy()\n",
    "pick_candidates_2['is_home'] = False\n",
    "pick_candidates_2.columns = ['week', 'team', 'probability', 'neutral','is_home']\n",
    "\n",
    "pick_candidates = pick_candidates_1.append(pick_candidates_2).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy results\n",
    "Below are the results for the best picksets according to the greedy strategy of picking the most lopsided matchups and eliminating that team and week from the selection set until each week has been picke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  week team probability neutral is_home\n",
      "0    1  PHI     0.76547       0    True\n",
      "Score: 0.7654698543324963\n",
      "  week team probability neutral is_home\n",
      "1    1  PHI     0.76547       0    True\n",
      "0    2  BAL    0.832054       0    True\n",
      "Score: 0.6369120212695885\n",
      "  week team probability neutral is_home\n",
      "2    1  PHI     0.76547       0    True\n",
      "1    2  BAL    0.832054       0    True\n",
      "0    3   NE    0.881352       0    True\n",
      "Score: 0.5613438281661964\n",
      "  week team probability neutral is_home\n",
      "3    1  PHI     0.76547       0    True\n",
      "1    2  BAL    0.832054       0    True\n",
      "0    3   NE    0.881352       0    True\n",
      "2    4  LAR    0.822693       0    True\n",
      "Score: 0.46181374931246544\n",
      "  week team probability neutral is_home\n",
      "4    1  SEA    0.761715       0    True\n",
      "1    2  BAL    0.832054       0    True\n",
      "0    3   NE    0.881352       0    True\n",
      "3    4  LAR    0.822693       0    True\n",
      "2    5  PHI    0.830608       0    True\n",
      "Score: 0.3817042855851708\n",
      "  week team probability neutral is_home\n",
      "4    1  SEA    0.761715       0    True\n",
      "1    2  BAL    0.832054       0    True\n",
      "0    3   NE    0.881352       0    True\n",
      "3    4  LAR    0.822693       0    True\n",
      "2    5  PHI    0.830608       0    True\n",
      "5    6   KC    0.735405       0    True\n",
      "Score: 0.28070727461727835\n",
      "  week team probability neutral is_home\n",
      "4    1  SEA    0.761715       0    True\n",
      "1    2  BAL    0.832054       0    True\n",
      "0    3   NE    0.881352       0    True\n",
      "3    4  LAR    0.822693       0    True\n",
      "2    5  PHI    0.830608       0    True\n",
      "5    6   KC    0.735405       0    True\n",
      "6    7  BUF    0.682858       0    True\n",
      "Score: 0.19168315931701094\n",
      "  week team probability neutral is_home\n",
      "5    1  SEA    0.761715       0    True\n",
      "2    2  BAL    0.832054       0    True\n",
      "0    3   NE    0.881352       0    True\n",
      "4    4  LAR    0.822693       0    True\n",
      "3    5  PHI    0.830608       0    True\n",
      "6    6   KC    0.735405       0    True\n",
      "7    7  BUF    0.682858       0    True\n",
      "1    8   NO    0.846187       0    True\n",
      "Score: 0.16219976775347422\n",
      "  week team probability neutral is_home\n",
      "6    1  CHI    0.758449       0    True\n",
      "2    2  BAL    0.832054       0    True\n",
      "0    3   NE    0.881352       0    True\n",
      "4    4  LAR    0.822693       0    True\n",
      "3    5  PHI    0.830608       0    True\n",
      "7    6   KC    0.735405       0    True\n",
      "8    7  BUF    0.682858       0    True\n",
      "1    8   NO    0.846187       0    True\n",
      "5    9  SEA    0.783849       0    True\n",
      "Score: 0.1265948713522135\n",
      "  week team probability neutral is_home\n",
      "7    1  CHI    0.758449       0    True\n",
      "2    2  BAL    0.832054       0    True\n",
      "0    3   NE    0.881352       0    True\n",
      "4    4  LAR    0.822693       0    True\n",
      "3    5  PHI    0.830608       0    True\n",
      "8    6   KC    0.735405       0    True\n",
      "9    7  BUF    0.682858       0    True\n",
      "1    8   NO    0.846187       0    True\n",
      "6    9  SEA    0.783849       0    True\n",
      "5   10  IND    0.784967       0    True\n",
      "Score: 0.09937283429874229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1: 1 - PHI',\n",
       " '2: 1 - PHI, 2 - BAL',\n",
       " '3: 1 - PHI, 2 - BAL, 3 - NE',\n",
       " '4: 1 - PHI, 2 - BAL, 3 - NE, 4 - LAR',\n",
       " '5: 1 - SEA, 2 - BAL, 3 - NE, 4 - LAR, 5 - PHI',\n",
       " '6: 1 - SEA, 2 - BAL, 3 - NE, 4 - LAR, 5 - PHI, 6 - KC',\n",
       " '7: 1 - SEA, 2 - BAL, 3 - NE, 4 - LAR, 5 - PHI, 6 - KC, 7 - BUF',\n",
       " '8: 1 - SEA, 2 - BAL, 3 - NE, 4 - LAR, 5 - PHI, 6 - KC, 7 - BUF, 8 - NO',\n",
       " '9: 1 - CHI, 2 - BAL, 3 - NE, 4 - LAR, 5 - PHI, 6 - KC, 7 - BUF, 8 - NO, 9 - SEA',\n",
       " '10: 1 - CHI, 2 - BAL, 3 - NE, 4 - LAR, 5 - PHI, 6 - KC, 7 - BUF, 8 - NO, 9 - SEA, 10 - IND']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def greedy_picker(n, force=None):\n",
    "    # Assume the pickset needs to be the length n\n",
    "    # and return the best set. If we already picked some\n",
    "    # values, then let's store that in force and make sure the greedy\n",
    "    # picker returns those values\n",
    "    \n",
    "    viable_candidates = pick_candidates[pick_candidates.week <= n]\n",
    "    pickset = list()\n",
    "\n",
    "    if force is not None:\n",
    "        for elem in force:\n",
    "            add_index = viable_candidates.index[(viable_candidates.week == elem['week']) & \n",
    "                                                        (viable_candidates.team == elem['team'])][0]\n",
    "            \n",
    "            pickset.append(viable_candidates.loc[add_index])\n",
    "            selected_week = viable_candidates.loc[add_index]['week']\n",
    "            selected_team = viable_candidates.loc[add_index]['team']\n",
    "            \n",
    "            print(selected_week)\n",
    "            print(selected_team)\n",
    "            viable_candidates = viable_candidates[(viable_candidates.team != selected_team) &\n",
    "                                                 (viable_candidates.week != selected_week)]\n",
    "            \n",
    "    while len(pickset) < n:\n",
    "        best_pick = viable_candidates.probability.idxmax()\n",
    "        pickset.append(viable_candidates.loc[best_pick])\n",
    "        selected_week = viable_candidates.loc[best_pick]['week']\n",
    "        selected_team = viable_candidates.loc[best_pick]['team']\n",
    "        viable_candidates = viable_candidates[(viable_candidates.team != selected_team) &\n",
    "                                             (viable_candidates.week != selected_week)]\n",
    "    results = pd.concat(pickset, axis=1,ignore_index=True).T\n",
    "    results = results.sort_values(by='week')\n",
    "    return results\n",
    "\n",
    "def picks_to_string(picks):\n",
    "    picks = [\"{} - {}\" .format(week, team) for week, team in zip(picks.week, picks.team)]\n",
    "    return ', '.join(picks)\n",
    "    \n",
    "pick_results = list()\n",
    "for i in range(1, 11):\n",
    "    picks = greedy_picker(i)\n",
    "    print(picks)\n",
    "    picks_score = np.prod(picks.probability)\n",
    "    print(\"Score: \" + str(picks_score))\n",
    "    picks = picks_to_string(picks)\n",
    "    picks = str(i) + ': ' + picks\n",
    "    pick_results.append(picks)\n",
    "\n",
    "pick_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our greedy solution through brute force\n",
    "\n",
    "For each time horizon that can be calculated in a reasonable amount of time (ie. until I think it takes too long), I will iterate through all combinations and see how they score on the objective function. Then I store the rank and better solutions found compared to the greedy solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/798854/all-combinations-of-a-list-of-lists\n",
    "\n",
    "# List of sets of pickable teams\n",
    "weekly_pickables = pick_candidates.groupby('week')['team'].apply(list)\n",
    "# print([elem for elem in weekly_pickables[:3]])\n",
    "\n",
    "# Dictionary of weekly probabilities for team: Week - Team : Prob\n",
    "weekly_probabilities = {\"{} - {}\".format(week, team): prob for week, team, prob in zip(list(pick_candidates.week), \n",
    "                                                                                       list(pick_candidates.team), \n",
    "                                                                                       list(pick_candidates.probability))}\n",
    "# print(weekly_probabilities)\n",
    "def analyze_top_picks(n_weeks, force=None):\n",
    "    greedy_picks = greedy_picker(n_weeks, force=force)\n",
    "    greedy_score = np.prod(greedy_picks.probability)\n",
    "    print(\"Greedy picks: \" + picks_to_string(greedy_picks))\n",
    "    print(\"Greedy score: \" + str(greedy_score))\n",
    "    \n",
    "    all_sets = []\n",
    "    scored_higher = 0\n",
    "    total = 0\n",
    "    \n",
    "    weekly_candidates = weekly_pickables[:n_weeks].copy()\n",
    "    if force is not None:\n",
    "        # Replace each list with just the forced value\n",
    "        for elem in force:\n",
    "            print(elem['team'])\n",
    "            print(list(elem['team']))\n",
    "            weekly_candidates[elem['week']] = [elem['team']]\n",
    "            \n",
    "    for pickset in tqdm_notebook(itertools.product(*[elem for elem in weekly_candidates])):\n",
    "        # Validate pickset\n",
    "        \n",
    "        if len(set(pickset)) == len(pickset):\n",
    "        \n",
    "            pickset_score = np.prod([weekly_probabilities['{} - {}'.format(i + 1, elem)] for i, elem in enumerate(pickset)])\n",
    "    #         print(pickset_score)\n",
    "            if pickset_score > greedy_score:\n",
    "                scored_higher += 1\n",
    "                all_sets.append({'solution': pickset, 'score': pickset_score})\n",
    "                print(\"Found better\")\n",
    "            total += 1\n",
    "    \n",
    "    return({'better_sets' : all_sets,\n",
    "           'n_better': scored_higher,\n",
    "           'greedy_rank': scored_higher + 1,\n",
    "           'total_sets': total})\n",
    "        \n",
    "# analyze_top_picks(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy picks: 1 - PHI\n",
      "Greedy score: 0.7654698543324963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6363b976084d0a843f426c43ad8924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Greedy picks: 1 - PHI, 2 - BAL\n",
      "Greedy score: 0.6369120212695885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ad78b32f04429594adc881c58a9ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Greedy picks: 1 - PHI, 2 - BAL, 3 - NE\n",
      "Greedy score: 0.5613438281661964\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb91ed9cd7944f36992ea0ae259a8915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Greedy picks: 1 - PHI, 2 - BAL, 3 - NE, 4 - LAR\n",
      "Greedy score: 0.46181374931246544\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5350e232f04f6590cc98eb457420e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Greedy picks: 1 - SEA, 2 - BAL, 3 - NE, 4 - LAR, 5 - PHI\n",
      "Greedy score: 0.3817042855851708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2546eeaa0949f699cf7aa17adce1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found better\n",
      "\n",
      "Greedy picks: 1 - SEA, 2 - BAL, 3 - NE, 4 - LAR, 5 - PHI, 6 - KC\n",
      "Greedy score: 0.28070727461727835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc9547725e946329732972e32137e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found better\n",
      "Found better\n",
      "Found better\n",
      "Found better\n",
      "Found better\n",
      "Found better\n",
      "Found better\n",
      "Found better\n",
      "\n",
      "                                         better_sets  n_better  greedy_rank  \\\n",
      "0                                                 []         0            1   \n",
      "1                                                 []         0            1   \n",
      "2                                                 []         0            1   \n",
      "3                                                 []         0            1   \n",
      "4  [{'solution': ('PHI', 'BAL', 'NE', 'LAR', 'NO'...         1            2   \n",
      "5  [{'solution': ('CHI', 'BAL', 'DAL', 'LAR', 'NO...         8            9   \n",
      "\n",
      "   total_sets  \n",
      "0          32  \n",
      "1         992  \n",
      "2       29760  \n",
      "3      809100  \n",
      "4    21241920  \n",
      "5   502147296  \n"
     ]
    }
   ],
   "source": [
    "pickset_brute_force = [analyze_top_picks(i) for i in range(1, 7)]   # top 6\n",
    "\n",
    "pickset_brute_force_results = pd.DataFrame(pickset_brute_force)\n",
    "print(pickset_brute_force_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy optimization analysis results\n",
    "\n",
    "The greedy strategy yields the best results until the time horizon is 5 or more weeks. This suggests if we are searching for a solution for a surivivor league that is expected to go 5 or more weeks, we can't just go down the list of probabilities eliminating teams and weeks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the greedy pickset\n",
    "\n",
    "At the same time that the greedy algorithm stops working, the ability to brute force also conveniently disappears. The optimization space is BIG, think of the number of teams you can pick each week being around 32 and the number of permutations as around $_{32} P _H$. Or more simply, for the 6 weeks I ran the optimization, I scored 502,147,296 valid sets.\n",
    "\n",
    "### Searching for a better pickset\n",
    "There are many ways to efficiently explore a space, my first thought was to test a metaheuristic algorithm on the optimal greedy pickset. Metaheuristics are algorithms that will find better or equal solutions the longer you search with no guarantee of finding the global optimum. I decided to use a simulated annealer to iterate on the greedy best pickset. The short explanation of this algorithm is that on each iteration, you look for a slightly different solution and evaluate the new solution. If it is better, you accept the solution and that is your new current solution. If it is worse, you can accept to pivot to that solution with some probability to avoid getting stuck in a local optimum. As iterations pass, the probability of accepting a worse solution tends towards zero. The best solution is stored and updated throughout the process.\n",
    "\n",
    "Using a simulated annealer, I would test minor changes to the best greedy pickset and see if I can beat it in a reasonable number of iterations. A new pickset is generated on each generation by swapping two teams in the set or picking up a completely new team to the set.\n",
    "\n",
    "### Evaluating whether or not this works\n",
    "\n",
    "My first step is to run it on a 6 week horizon to see if I can pick up a better solution than the greedy set. If I don't find any better solutions, then the implementation and parameters of the annealer are off.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def perturb_pickset(old_pickset, force=None):\n",
    "    # This function returns a slightly different pickset\n",
    "    # The goal is to swap two picks and validate that we didn't pick bye weeks\n",
    "    \n",
    "    p_swap = 0.2\n",
    "    uniform = random.random()\n",
    "    \n",
    "    valid_swap = False\n",
    "    \n",
    "    ignore = []\n",
    "    if force is not None:\n",
    "        ignore = [elem['week'] - 1 for elem in force]\n",
    "    \n",
    "    index_candidates = list(range(len(old_pickset)))\n",
    "    index_candidates = [elem for elem in index_candidates if not elem in ignore]\n",
    "    \n",
    "    if uniform < p_swap:\n",
    "        while not valid_swap:\n",
    "            indices_to_swap = random.sample(index_candidates, 2)\n",
    "            valid_swap = old_pickset[indices_to_swap[0]] in weekly_pickables[indices_to_swap[1] + 1] \n",
    "            valid_swap = valid_swap and old_pickset[indices_to_swap[1]] in weekly_pickables[indices_to_swap[0] + 1]\n",
    "            new_pickset = old_pickset.copy()\n",
    "            new_pickset[indices_to_swap[0]], new_pickset[indices_to_swap[1]] = new_pickset[indices_to_swap[1]], new_pickset[indices_to_swap[0]]\n",
    "        return new_pickset\n",
    "    else:\n",
    "        while not valid_swap:\n",
    "            index_to_change = random.sample(index_candidates, 1)[0]\n",
    "            candidates = weekly_pickables[index_to_change + 1].copy()\n",
    "            new_elem = random.sample(candidates, 1)[0]\n",
    "            valid_swap = new_elem not in old_pickset    # Avoid using already selected at any week including index\n",
    "            new_pickset = old_pickset.copy()\n",
    "            new_pickset[index_to_change] = new_elem\n",
    "        return new_pickset\n",
    "\n",
    "def temperature(t_0, i, cooling_rate):\n",
    "    return t_0 * (cooling_rate  ** i)\n",
    "\n",
    "def simulated_annealer(starting_pickset, max_iter=10000, force=None):\n",
    "    \n",
    "    current_score = np.prod([weekly_probabilities['{} - {}'.format(i + 1, elem)] for i, elem in enumerate(starting_pickset)])\n",
    "    best_score = current_score\n",
    "    \n",
    "    \n",
    "    current_solution = starting_pickset\n",
    "    best_solution = current_solution\n",
    "    \n",
    "    annealer_results = [{'i': 0,\n",
    "                        'score': current_score,\n",
    "                        'best_score': best_score}]\n",
    "    \n",
    "    temp = -0.05 / np.log(0.20)    # I want a 20% chance of accepting a 5% decrease at start\n",
    "    \n",
    "    cooling_rate = (-0.05 / (temp * np.log(0.0001))) ** (1 / max_iter)   # At max iter I want a 0.01% chance   \n",
    "\n",
    "    print(\"Temp: \" + str(temp))\n",
    "    \n",
    "    print(\"Cooling rate: {}\".format(cooling_rate))\n",
    "    for iteration in tqdm_notebook(range(1, max_iter + 1)):\n",
    "        \n",
    "        new_solution = perturb_pickset(current_solution, force=force)\n",
    "        new_score = np.prod([weekly_probabilities['{} - {}'.format(i + 1, elem)] for i, elem in enumerate(new_solution)])\n",
    "        \n",
    "        new_temp = temperature(temp, iteration, cooling_rate)\n",
    "        \n",
    "        accept_prob =  np.exp((new_score - current_score)/new_temp) \n",
    "\n",
    "        if random.random() < accept_prob:\n",
    "            current_solution = new_solution\n",
    "            current_score = new_score\n",
    "            \n",
    "        if new_score > best_score:\n",
    "            print(\"Found better\")\n",
    "            best_score = new_score\n",
    "            best_solution = current_solution\n",
    "            print(\"New best score: \" + str(best_score))\n",
    "            print(\"New best solution: \" + ', '.join(best_solution))\n",
    "        \n",
    "#         annealer_results.append({'i': iteration,\n",
    "#                                  'score': current_score,\n",
    "#                                  'best_score': best_score,\n",
    "#                                 'acceptance': accept_prob})\n",
    "        \n",
    "    return {'starting_solution': starting_pickset,\n",
    "           'best_solution': best_solution,\n",
    "           'iteration_summary': annealer_results}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the simulated annealer\n",
    "\n",
    "Let's test to see if we find the brute force top solutions for 6 week pickset in 1,000,000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp: 0.031066746727980595\n",
      "Cooling rate: 0.9999982555597104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d3a3663bc7455e8539fdf8f040ff26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found better\n",
      "New best score: 0.2909249896402786\n",
      "New best solution: CHI, BAL, DAL, LAR, NO, NE\n",
      "Found better\n",
      "New best score: 0.2936182269111819\n",
      "New best solution: PHI, BAL, DAL, LAR, NO, NE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(100)\n",
    "greedy_pickset = list(greedy_picker(6).team)\n",
    "# perturb_pickset(greedy_pickset)\n",
    "annealer_results = simulated_annealer(greedy_pickset, 1000000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for evaluating the annealer\n",
    "\n",
    "The above outputs show that we can find better solutions than the greedy solution. On future iterations, I should store the best value found to see if these are global optima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So how long should I expect the contest to go on for anyway?\n",
    "\n",
    "At this point, it might be worth addressing what a reasonable value for the time horzion, $H$ is. \n",
    "\n",
    "Figuring out a good guess for how long we can go on is to estimate the longevity of likely opponent strategies. I just need to beat the 2nd place person to win. So what are reasonable strategies that the second best person could use?\n",
    "\n",
    "1. <b>Greedy strategy</b>: If we really optimized things according to the estimates here, how long until it is unlikely that anyone is left? Looking at the greedy optimizer results, it looks like we have a 27.8% chance of making it until week 6.\n",
    "2. <b>Dolphin streaming</b>: If you choose to pick against the dolphins and we assume they are as hopeless as we think, how long until you have to pick a repeat (ie. a non-risk free matchup)? Supposedly by their bye on week 5 or their repeat against the Bills in week 11, you would have to pick a team that could lose. I would assume week 5 you could find a reasonably good matchup, then this strategy could carry you to week 11.\n",
    "\n",
    "So the scenarios we have to plan for are <b>6 Weeks and 11 Weeks.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what am I supposed to do from here on out?\n",
    "\n",
    "<img src='nb_files/chargers.jpeg'>\n",
    "\n",
    "\n",
    "I picked the Chargers in week 1 because I felt like I wouldn't be confident in them again after their match against the Luck-less Colts. I needed to find what the next pick should be given that I already picked LAC week 1. Below I look at what the various strategies suggest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Selector for 6 Weeks\n",
    "The greedy selector for 6 weeks suggest my next pick is <b>BAL</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "LAC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>team</th>\n",
       "      <th>probability</th>\n",
       "      <th>neutral</th>\n",
       "      <th>is_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>LAC</td>\n",
       "      <td>0.626264</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>BAL</td>\n",
       "      <td>0.832054</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.881352</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>LAR</td>\n",
       "      <td>0.822693</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>PHI</td>\n",
       "      <td>0.830608</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>KC</td>\n",
       "      <td>0.735405</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  week team probability neutral is_home\n",
       "0    1  LAC    0.626264       0    True\n",
       "2    2  BAL    0.832054       0    True\n",
       "1    3   NE    0.881352       0    True\n",
       "4    4  LAR    0.822693       0    True\n",
       "3    5  PHI    0.830608       0    True\n",
       "5    6   KC    0.735405       0    True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_picker(6, force=[{'week': 1, 'team': 'LAC'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute force over 6 weeks\n",
    "\n",
    "Brute force over a 6 week horizon suggests that I should pick <b>BAL</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "LAC\n",
      "Greedy picks: 1 - LAC, 2 - BAL, 3 - NE, 4 - LAR, 5 - PHI, 6 - KC\n",
      "Greedy score: 0.23079109269671488\n",
      "LAC\n",
      "['L', 'A', 'C']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e3426a00784ef4b529ac61dc26be1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found better\n",
      "Found better\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'better_sets': [{'solution': ('LAC', 'BAL', 'DAL', 'LAR', 'NO', 'NE'),\n",
       "   'score': 0.24022195187722442},\n",
       "  {'solution': ('LAC', 'BAL', 'DAL', 'LAR', 'PHI', 'NE'),\n",
       "   'score': 0.24119231677793931}],\n",
       " 'n_better': 2,\n",
       " 'greedy_rank': 3,\n",
       " 'total_sets': 15553944}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_top_picks(6, force=[{'week': 1, 'team': 'LAC'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated annealer over 11 week greedy pick\n",
    "\n",
    "And yet again, my optimizers suggest <b>BAL</b> for week 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "LAC\n",
      "['LAC', 'BAL', 'NE', 'LAR', 'PHI', 'KC', 'BUF', 'NO', 'SEA', 'IND', 'MIN']\n",
      "Temp: 0.031066746727980595\n",
      "Cooling rate: 0.9999982555597104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4901c443a926451bbba24ed7fade5bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'starting_solution': ['LAC',\n",
       "  'BAL',\n",
       "  'NE',\n",
       "  'LAR',\n",
       "  'PHI',\n",
       "  'KC',\n",
       "  'BUF',\n",
       "  'NO',\n",
       "  'SEA',\n",
       "  'IND',\n",
       "  'MIN'],\n",
       " 'best_solution': ['LAC',\n",
       "  'BAL',\n",
       "  'NE',\n",
       "  'LAR',\n",
       "  'PHI',\n",
       "  'KC',\n",
       "  'BUF',\n",
       "  'NO',\n",
       "  'SEA',\n",
       "  'IND',\n",
       "  'MIN'],\n",
       " 'iteration_summary': [{'i': 0,\n",
       "   'score': 0.06195685260812797,\n",
       "   'best_score': 0.06195685260812797}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(100)\n",
    "starting_pickset = list(greedy_picker(11, force=[{'week': 1, 'team': 'LAC'}]).team)\n",
    "print(starting_pickset)\n",
    "simulated_annealer(starting_pickset, 1000000, force=[{'week': 1, 'team': 'LAC'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To be honest though, I don't feel that great about BAL in Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
